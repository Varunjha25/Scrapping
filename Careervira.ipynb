{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2284426d-8079-439c-a15c-3803080ad31c",
   "metadata": {},
   "source": [
    "### Here, I use the Education Platform website to scrape course details. I scrape each of the ten courses individually, merge the results, and save the file as an Excel spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dc821c66-2154-4edb-aadc-650d5b283cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-lucknow/supply-chain-management\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"05 May, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '218000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c5a8e-a438-44b6-bf6f-b8f24ef8dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/opjindal-global-business-school/masters-of-business-administration-opj-global-university\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"URL\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '165000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "file_name = 'course_details.xlsx'\n",
    "\n",
    "try:\n",
    "    existing_df = pd.read_excel(file_name)\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "except FileNotFoundError:\n",
    "    updated_df = df\n",
    "\n",
    "updated_df.to_excel(file_name, index=False)\n",
    "\n",
    "print(f\"Data has been saved to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0b08117-4b44-4324-bb99-88ce347daeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-lucknow/supply-chain-management\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"05 May, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '218000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details3.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details3.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d5de8655-f7c5-4ad4-85a2-815a0b2d7112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details4.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/goa-institute-of-management/exectuive-pg-program-in-health-care-management\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"31 Mar, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '97458' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details4.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details4.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3fe93df4-f355-4f7e-851c-04ec2af0fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details5.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-lucknow/advanced-program-in-strategic-management-for-business-excellence\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"30 Jun, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '312000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details5.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details5.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ed3c869-7308-4830-81b7-1e5c961bdaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details6.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-raipur/executive-certificate-program-in-general-management\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"30 Jun, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '160000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details6.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details6.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a19d2ed6-f068-4e99-ab6d-fc123529ff86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details7.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-raipur/executive-certificate-program-in-general-management\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"30 Jun, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '160000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details7.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details7.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9f457b6-e4d8-40f1-bb25-9c66da444593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details8.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-kozhikode/applied-financial-risk-management-course\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"30 Jun, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '100000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details8.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details8.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9961124d-341b-48ae-b64b-21848c7ec0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details9.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/xlri-jamshedpur/ecommerce-supply-chain-management-and-analytics\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"30 Jun, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '165000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details9.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details9.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b411cb9-491a-4d4b-b0de-7c44bc8f9769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to course_details10.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://talentedge.com/iim-kozhikode/supply-chain-strategy-management-course\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "}\n",
    "\n",
    "# Send GET request with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract data\n",
    "data = {\n",
    "    \"Course link\": url,\n",
    "    \"Title\": soup.find('h1').get_text(strip=True),\n",
    "    \"Description\": soup.find('div', class_=\"desc_less\").find('p').get_text(strip=True) if soup.find('div', class_=\"desc_less\") else \"Description not found.\",\n",
    "    \"Duration\": soup.find('p', string=lambda x: x and 'Duration' in x).get_text(strip=True).replace('Duration: ', '') if soup.find('p', string=lambda x: x and 'Duration' in x) else \"Duration not found.\",\n",
    "    \"Course Start\": soup.find('p', string=\"30 Jun, 2024\").get_text(strip=True) if soup.find('p', string=\"05 May, 2024\") else \"Course start date not found.\",\n",
    "    \"Key Skills\": \", \".join([skill.get_text(strip=True) for skill in soup.find('div', class_='key-skills-sec').find('ul').find_all('li')]) if soup.find('div', class_='key-skills-sec') else \"Key skills not found.\",\n",
    "    \"What will you learn\": \", \".join([item.get_text(strip=True) for item in soup.find('div', class_='pl-deeper-undstnd to_flex_ul').find('ul').find_all('li')]) if soup.find('div', class_='pl-deeper-undstnd to_flex_ul') else \"Understanding items not found.\",\n",
    "    \"Target Student\": soup.find('h4', class_=\"cs-titlec\").get_text(strip=True) if soup.find('h4', class_=\"cs-titlec\") else \"Target student information not found.\",\n",
    "    \"Eligibility Criteria\": soup.find('div', class_='eligible-right-top-list').find('ul').find('li').get_text(strip=True) if soup.find('div', class_='eligible-right-top-list') else \"Criteria not found.\",\n",
    "    \"Faculty Names\": \", \".join([h4.get_text(strip=True) for h4 in soup.find_all('h4', class_=\"best-fname\")]),\n",
    "    \"Institute\": soup.find('h4', class_=\"about-ititle\").get_text(strip=True) if soup.find('h4', class_=\"about-ititle\") else \"Institute not found.\",\n",
    "    \"Fee + GST\": None\n",
    "}\n",
    "\n",
    "# Extract fee amount and GST\n",
    "fees = soup.find_all('div', class_='program-details-total-pay-amt-right')\n",
    "for div in fees:\n",
    "    text = div.get_text(strip=True, separator=' ')\n",
    "    if '180000' in text:\n",
    "        data[\"Fee + GST\"] = ' '.join(text.split()[1:4])\n",
    "        break\n",
    "\n",
    "if data[\"Fee + GST\"] is None:\n",
    "    data[\"Fee + GST\"] = \"Fee not found.\"\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('course_details10.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to course_details10.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77521fe6-5a1d-4646-ae64-fa349fbef469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been saved to combined_course_details.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "file1 = 'course_details.xlsx'\n",
    "file2 = 'course_details3.xlsx'\n",
    "file3 = 'course_details4.xlsx'\n",
    "file4 = 'course_details5.xlsx'\n",
    "file5 = 'course_details6.xlsx'\n",
    "file6 = 'course_details7.xlsx'\n",
    "file7 = 'course_details8.xlsx'\n",
    "file8 = 'course_details9.xlsx'\n",
    "file9 = 'course_details10.xlsx'\n",
    "\n",
    "combined_file = 'combined_course_details.xlsx'\n",
    "\n",
    "# Read the existing Excel files\n",
    "df1 = pd.read_excel(file1)\n",
    "df2 = pd.read_excel(file2)\n",
    "df3 = pd.read_excel(file3)\n",
    "df4 = pd.read_excel(file4)\n",
    "df5 = pd.read_excel(file5)\n",
    "df6 = pd.read_excel(file6)\n",
    "df8 = pd.read_excel(file8)\n",
    "df9 = pd.read_excel(file9)\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "combined_df.to_excel(combined_file, index=False)\n",
    "\n",
    "print(f\"Combined data has been saved to {combined_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d0927-8ccd-408b-8b86-fe3e46efae69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e9eb2f7b-752b-493c-b436-152b7bb78f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3631966056.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[141], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    import pandas as pd = pd.read_excel('combined_course_details.xlsx')\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('combined_course_details.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59096a7e-0bbd-4546-9f00-2589cb2e5927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
